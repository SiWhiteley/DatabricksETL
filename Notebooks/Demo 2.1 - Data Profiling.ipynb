{"cells":[{"cell_type":"code","source":["#Gather relevant keys from our Secret Scope\nServicePrincipalID = dbutils.secrets.get(scope = \"Analysts\", key = \"SPID\")\nServicePrincipalKey = dbutils.secrets.get(scope = \"Analysts\", key = \"SPKey\")\nDirectoryID = dbutils.secrets.get(scope = \"Analysts\", key = \"DirectoryID\")\nDBUser = dbutils.secrets.get(scope = \"Analysts\", key = \"DBUser\")\nDBPassword = dbutils.secrets.get(scope = \"Analysts\", key = \"DBPword\")\n\n\n#Combine DirectoryID into full string\nDirectory = \"https://login.microsoftonline.com/{}/oauth2/token\".format(DirectoryID)\n\n#Configure our ADLS Gen 2 connection with our service principal details\nspark.conf.set(\"fs.azure.account.auth.type\", \"OAuth\")\nspark.conf.set(\"fs.azure.account.oauth.provider.type\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\nspark.conf.set(\"fs.azure.account.oauth2.client.id\", ServicePrincipalID)\nspark.conf.set(\"fs.azure.account.oauth2.client.secret\", ServicePrincipalKey)\nspark.conf.set(\"fs.azure.account.oauth2.client.endpoint\", Directory)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["### Data Profiling Basics\n\nOne of the first jobs when developing a new data pipeline is to understand the data that you're working with. We'll briefly look at three different methods of getting to grips with a new dataset:\n - Using HEAD to peek at a file before trying to load it\n - Using the inbuilt describe() function\n - Importing specialist profiling libraries such as pandas_profiling"],"metadata":{}},{"cell_type":"code","source":["# Create DataFrame using one of our Taxi files\nSampledf = (spark\n             .read\n             .option(\"header\",\"true\")\n             .option(\"inferSchema\",\"true\")\n             .csv(\"/mnt/taxi/taxiFull/fhv_tripdata_2017-01.csv\")\n           )\n\ndisplay(Sampledf.describe())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>summary</th><th>Dispatching_base_num</th><th>PUlocationID</th><th>DOlocationID</th></tr></thead><tbody><tr><td>count</td><td>13657212</td><td>9952802</td><td>106013</td></tr><tr><td>mean</td><td>null</td><td>143.67607021620645</td><td>3.4901380019431577E-4</td></tr><tr><td>stddev</td><td>null</td><td>74.64678850663316</td><td>0.11363762848277774</td></tr><tr><td>min</td><td>B00001</td><td>0</td><td>0</td></tr><tr><td>max</td><td>b02881</td><td>265</td><td>37</td></tr></tbody></table></div>"]}}],"execution_count":3},{"cell_type":"code","source":["import spark_df_profiling as spkprof\n\ntaxiProfiling = spkprof.ProfileReport(Sampledf)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["str(taxiProfiling)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">46</span><span class=\"ansired\">]: </span>&apos;Output written to file /tmp/profile.html&apos;\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["dbutils.fs.ls(\"/tmp/\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">47</span><span class=\"ansired\">]: </span>[FileInfo(path=&apos;dbfs:/tmp/hive/&apos;, name=&apos;hive/&apos;, size=0)]\n</div>"]}}],"execution_count":6}],"metadata":{"name":"Demo 2.1 - Data Profiling","notebookId":928472775918023},"nbformat":4,"nbformat_minor":0}
